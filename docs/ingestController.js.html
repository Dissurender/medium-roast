<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <title>JSDoc: Source: ingestController.js</title>

    <script src="scripts/prettify/prettify.js"> </script>
    <script src="scripts/prettify/lang-css.js"> </script>
    <!--[if lt IE 9]>
      <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    <link type="text/css" rel="stylesheet" href="styles/prettify-tomorrow.css">
    <link type="text/css" rel="stylesheet" href="styles/jsdoc-default.css">
</head>

<body>

<div id="main">

    <h1 class="page-title">Source: ingestController.js</h1>

    



    
    <section>
        <article>
            <pre class="prettyprint source linenums"><code>const base = 'https://hacker-news.firebaseio.com/';
import { createQuery, checkDB } from '../db/index.js';
import { logger } from '../utils/winston.js';
import WorkQueue from '../utils/workQueue.js';

/**
 * Retrieves the most recent story from the Hacker News API and traverses the IDs
 * 100 most revcent stories. It then passes the retrieved stories to the {@link ingestData}
 * @async
 * @returns {Promise&lt;Story>} - Story object
 *
 */
export async function getMostRecentStory() {
  const story = await fetch(base + `v0/maxitem.json`).then(
    processChunkedResponse
  );

  logger.info('the story: ' + story.id);

  // create an array of the 100 most recent stories from the most recent story id
  const ids = Array.from({ length: 100 }, (_, i) => story - i);
  const result = await ingestData(ids, 'story');

  logger.info(`${result.length} items ingested`);
}

/**
 * retrieves the top stories from the Hacker News API.
 * It then passes the retrieved stories to the {@link ingestData}
 * function to process and store them in a database.
 * @async
 */
export async function getTopStories() {
  logger.info('starting Top Stories..');
  const topStories = await fetch(base + 'v0/topstories.json').then(
    processChunkedResponse
  );

  // With the Interger[] we pass to the ingestor to fulfull the data
  const result = await ingestData(topStories.slice(0, 100), 'story');

  logger.info(`${result.length} items ingested`);
}

/**
 * This helper function receives a ByteStream and mutates
 * into a String using 9th Level Magic then parses to Json.
 * @param {Promise&lt;Response>} response - Response
 * @returns Object of accumulated http chunks received
 */
function processChunkedResponse(response) {
  let text = '';
  const reader = response.body.getReader();
  const decoder = new TextDecoder();

  return readChunk().catch((error) => {
    logger.error('Error reading chunk: ' + error);
    throw new Error(error);
  });

  function readChunk() {
    return reader.read().then(appendChunks);
  }

  function appendChunks(result) {
    const chunk = decoder.decode(result.value || new Uint8Array(), {
      stream: !result.done,
    });

    text += chunk;

    if (result.done) {
      try {
        return JSON.parse(text);
      } catch (error) {
        logger.error('Error parsing JSON:' + error);
        throw new Error(error);
      }
    } else {
      return readChunk();
    }
  }
}

/**
 * Fetches a story from the Hacker News API
 * @param {Number} id - ID of the story
 * @returns {Promise&lt;Story>} - Story object
 */
export async function fetchFromHN(id) {
  return await fetch(base + `v0/item/${id}.json`).then(processChunkedResponse);
}

/**
 * This is where the magic is, implementing a simple
 * work queue to hold a local copy of data and draining
 * it to mutate and store into the result array
 * @param {Array&lt;Number>} data - Array of IDs
 * @param {String} type
 * @returns {Array&lt;Object>}
 */
export async function ingestData(data, type) {
  // return if data is bad and log the error
  if (data === null) {
    logger.error('IngestData parameter `data` is null.');
    return;
  }

  // instantiate a new work queue
  const work = new WorkQueue();
  work.enqueue(data);

  let result = [];

  while (!work.done()) {
    const item = work.dequeue();
    let selectItem = await checkDB(item.item, type);

    if (selectItem === null) {
      logger.info(`${type} not found.`);

      selectItem = await fetchFromHN(item.item);
      createQuery(selectItem, type);
    } else {
      logger.info('story found.');
    }

    result.push(selectItem);
  }

  return result;
}

/**
 * getComments is a helper function for {@link ingestData}
 * to recurse the kids(Comments) field and build out comment trees
 * @param {Story} item
 * @param type
 */
export async function getComments(item, type) {
  // validate input item for escape clause
  if (!item.kids || typeof item !== 'object') {
    logger.warn(`${item} is not valid.`);
    return item;
  }
  logger.info('Getting comments for ' + item.id);

  const kids = await ingestData(item.kids, type);

  let newKids = [];
  for (let i = 0; i &lt; kids.length; i++) {
    const temp = await getComments(kids[i], 'comment');
    newKids.push(temp);
  }

  const newItem = { ...item, kids: newKids };

  return newItem;
}
</code></pre>
        </article>
    </section>




</div>

<nav>
    <h2><a href="index.html">Home</a></h2><h3>Global</h3><ul><li><a href="global.html#fetchFromHN">fetchFromHN</a></li><li><a href="global.html#getComment">getComment</a></li><li><a href="global.html#getComments">getComments</a></li><li><a href="global.html#getMostRecentStory">getMostRecentStory</a></li><li><a href="global.html#getRecentStories">getRecentStories</a></li><li><a href="global.html#getStories">getStories</a></li><li><a href="global.html#getStory">getStory</a></li><li><a href="global.html#getTopStories">getTopStories</a></li><li><a href="global.html#ingestData">ingestData</a></li><li><a href="global.html#processChunkedResponse">processChunkedResponse</a></li></ul>
</nav>

<br class="clear">

<footer>
    Documentation generated by <a href="https://github.com/jsdoc/jsdoc">JSDoc 4.0.4</a> on Thu Jan 02 2025 19:27:38 GMT-0600 (Central Standard Time)
</footer>

<script> prettyPrint(); </script>
<script src="scripts/linenumber.js"> </script>
</body>
</html>
